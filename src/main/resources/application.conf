outputDir = "output"

files {
  trainingPath = "/Users/enrique/Downloads/qangaroo_v1.1/wikihop/train.json"
  testingPath = "/Users/enrique/Downloads/qangaroo_v1.1/wikihop/dev.json"
  annotationsFile = ${outputDir}/annotations_openie.txt
  openIEAnnotationsFile = ${outputDir}/openie_annotations.ser_deleteme
  entityListFile = ${outputDir}/entities2.tsv
  graphvizDir = ${outputDir}/graphviz
  benchmarkOutput = ${outputDir}/benchmark_deps.json
  glovePath = "glove/glove.6B.50d.txt"

  hotpotqa {
    jsonPath = "/Users/enrique/Downloads/hotpot_train_v1.1.json"
  }
}

pathFinder{
  knowledgeGraphType = "Cooccurrence" #NamedEntityLink, Cooccurrence, OpenIE
  outputFile = newentities/cooccurrence_related_results_newGrounding.ser#${outputDir}/openie_related_results.ser
}

lucene {
  directoryIndex = "WikiHopLuceneIndex"
  hotpotqa{
    directoryIndex = "HotPotLuceneIndex"
  }
}

embeddings {
  dimensions = 200
  model = skipgram #skipgram, cbow
  binaryMatrix = false #true in case you want to store the matrix as a binary file
  binaryPath = "./word2vec" # Path to the word2vec executable binary
  threads = 12
  embeddingsFile = ${outputDir}/wikihop_vectors.txt
  vocabularyFile = "w2vvoc.txt"
}

environment {
  knowledgeGraphType = Coocurrence #Coocurrence, OpenIE, NamedEntityLink
  documentUniverse = AllDocs#Local, Random, Related, AllDocs
  successReward = 100
  failureReward = -100
  livingReward = 1
  cacheAnnotations = false
  topEntitiesNum = 10
  maxIterations = 10
  immediateRewardEnabled = false
  entitySelection = lucene #distance, rank, lucene
  excludeExplorationSingle = true # Don't consider exploration "single" actions
  maxPapersFetched = 10 # -1 for all the hits, positive for a defined value
}

benchmark {
  agentType = Cascade #Random, Cascade
  # These are optional parameters, used to split the work on multiple instances (mainly for the HPC)
  #totalWorkers = 3
  #workerIndex = 1
  #numInstances = 10
  ######
}

training {
  approximator = dqn #dqn or linear or mlp or bqn
  episodes = 5000
  targetUpdate = 10
  transitionMemorySize = 100000
  epsilon {
    upperBound = 0.3
    lowerBound = 0
    kind = linear #linear, exponential
    length = 0.75 # This is the portion of the number of epoch by wich the decay will be finished
  }
  modelName = "model_scala.pt"
  statsDump = "training.tsv"
  maxThreads = 4
  instances = "training_multinomial.txt"
}

testing {
  agentType = Policy // Policy, Cascade, Random, Exploit, Explore, Exploit, BalancedRandom
  approximator = mlp #dqn or linear only holds if the agent is the policy agent
  modelName = "trial29b.pt" // This only holds if the agent is the policy agent
  statsDump = "trial29b_eval.tsv"
  maxThreads = 12
  instances = "testing_instances.txt"
  exploreBias = .5
}

random {
  seed = 1024
}

httpClient {
  server = "http://127.0.0.1:5000"
//  server = "http://192.168.1.42:5000"
}
